% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{edm_template}

%\usepackage{amsmath} % might need this later..
%\usepackage{graphicx} % might need this later..
\usepackage{url,paralist,multirow}
\usepackage{color, colortbl}
\definecolor{Gray}{gray}{0.9}


\renewcommand{\arraystretch}{1.55}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\mgr}[1]{\textsc{#1}}
\newcommand{\ftr}[1]{\textsc{#1}}

\newcommand{\comment}[1]{}

\begin{document}

\title{Student Profiling from Tutoring System Log Data: \\When do Multiple Graphical Representations Matter?}
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
% 2nd. author
%\comment{
\alignauthor 
Ryan Carlson\\
       \affaddr{Language Technologies Institute}\\
       \affaddr{Carnegie Mellon University}\\
       \affaddr{Pittsburgh, PA, USA}\\
       \email{ryancarlson@cmu.edu}
% 3rd. author
\alignauthor 
Konstantin Genin\\
       \affaddr{Department of Philosophy}\\
       \affaddr{Carnegie Mellon University}\\
       \affaddr{Pittsburgh, PA, USA}\\
       \email{kgenin@andrew.cmu.edu}
%\alignauthor
%Helga Caballero\\
%      \affaddr{School of Public and International Affairs}\\
%       \affaddr{University of Pittsburgh}\\
%      \affaddr{Pittsburgh, PA 15260}\\
%       \email{hec33@pitt.edu}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor Martina Rau\\
       \affaddr{Human-Computer Interaction Institute}\\
       \affaddr{Carnegie Mellon University}\\
       \affaddr{Pittsburgh, PA, USA}\\
       \email{marau@cs.cmu.edu}
% 5th. author
\alignauthor Richard Scheines\\
       \affaddr{Department of Philosophy}\\
       \affaddr{Carnegie Mellon University}\\
       \affaddr{Pittsburgh, PA, USA}\\      
        \email{scheines@cmu.edu}
% 6th. author
%\alignauthor Clark Glymour\\
%       \affaddr{Department of Philosophy}\\
%       \affaddr{Carnegie-Mellon University}\\
%       \affaddr{Pittsburgh, PA 15213}\\      
%        \email{cg09@andrew.cmu.edu}
}

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
We analyze log-data generated by an experiment with Fractions Tutor, an intelligent tutoring system.  The experiment compares the educational effectiveness of instruction with single and multiple graphical representations. We extract the error-making and hint-seeking behaviors of each student to characterize their learning strategy. Using an expectation-maximization approach, we cluster the students by learning strategy. We find that a) experimental condition and learning outcome are clearly associated b) experimental condition and learning strategy are not, and c) almost all of the association between experimental condition and learning outcome is found among students implementing just one of the learning strategies we identify. This class of students is characterized by relatively high rates of error as well as a marked reluctance to seek help. They also show the greatest educational gains from instruction with multiple rather than single representations. The behaviors that characterize this group illuminate the mechanism underlying the effectiveness of multiple representations and suggest strategies for tailoring instruction to individual students. Our methodology can be implemented in an on-line tutoring system to dynamically tailor individualized instruction.

\end{abstract}

%% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%
%\terms{Theory}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}
\label{sec:introduction}

Multiple graphical representations (MGRs) are ubiquitous in math and science instruction: they are frequently used to emphasize complementary conceptual interpretations of complex learning materials. Fraction instruction is one domain in which graphical representations, such as number lines, pie-charts, and rectangles are used to help students overcome the difficulty of the material. Although the educational psychology literature suggests that requiring students to translate between representations supports the creation of deep knowledge structures \cite{Ambrose2010},  the experimental results are somewhat ambiguous \cite{Ainsworth1999} and the mechanisms underlying these advantages are not well understood \cite{Ainsworth2006}. 

Because student interaction with intelligent tutoring systems (ITSs) generates very fine-grained behavioral and outcome data, these systems are well-suited for conducting experiments on the effect of MGRs on learning outcomes \cite{Newell1981}. Machine learning methods can be profitably applied to identify the kinds of students whose learning outcomes are improved by MGRs and the factors mediating their success \cite{Self1986}. Such insights enable developers of ITSs to design individualized instructional support that can make learning with MGRs even more effective. This may involve encouraging students to reflect on the material with self-explanation prompts \cite{Rau2009} or detecting ineffective strategies and implementing interventions on-the-fly. Work in the latter area ranges from detecting abuse of the ITS hint system and other ``gaming'' behaviors \cite{Baker2009,Baker2009b} to providing spontaneous help to students lacking the metacognitive skills to know when they could use a hint \cite{Aleven2000,Aleven2006,Aleven2003}.

Prior research conducted on elementary-school students working with a Fractions Tutor suggests that prompting students to self-explain while working with MGRs improves their educational effectiveness \cite{Rau2009}. Subsequent studies examining error-rate, hint-use and time-spent in tutor's log failed to identify variables that mediate the effectiveness of MGRs \cite{Rau2012}. The mechanisms by which multiple graphical representations improve learning outcomes remain poorly understood.

We conjecture that previous efforts to identify mediating factors were frustrated by heterogeneity in the problem-solving habits and behaviors of the student population under investigation. Using a mixture modeling technique, we cluster students by the patterns of interaction with the tutor in the log-data that characterize their learning strategy. Clustering based on student characteristics has proved successful in grouping students into meaningful subpopulations across both collaborative \cite{Perera2009} and individual \cite{Beal2008,Merceron2005,Amershi2009} educational environments. 

Four strategic profiles emerge from our analysis, each with a natural interpretation. Two of the profiles are characterized by a low propensity to seek help from the tutor. In one of these the students are simply confident: they make few errors, solicit little help and don't seem to need any. In the other the students are reluctant to solicit help even though they seem like they need it: they make a relatively large number of mistakes but make little use of the support mechanisms the tutor provides. We characterize this second class as ``stubborn'' without intending any pejorative connotations. A third class is highly interactive: they make many mistakes, seek assistance readily and frequently exhaust the hints available in a given problem. Students in the fourth class occupy a middle ground between the interactive and the stubborn: they make an average number of mistakes and will eventually seek help when they are having trouble.

We proceed to explore how the experimental conditions affect post-test outcomes. Confirming previous results \cite{Rau2012}, we find that students in the multiple-representation condition had greater learning gains than those in the single-representation condition. MGRs seem to have a robust and positive effect on long-term knowledge consolidation. We then explore the effect of multiple representations in the sub-populations defined by each strategic profile. We first establish independence between learning strategy and experimental condition. This suggests that we are detecting pre-existing strategic profiles, rather than artifacts of the experimental setup. Most interestingly, we discover that learning gains from MGRs depend heavily on learning strategy. Students exhibiting a ``stubborn'' profile profited substantially from instruction with multiple rather than single representations. For the remaining students, experimental condition and learning gain were independent. We conjecture that ``stubborn'' students lack the metacognitive skills to judge when their learning strategies are failing. These students are the most sensitive to pedagogical decisions because they are the least equipped to structure and manage their own learning. 

Section \ref{sec:experiment} of what follows describes the initial experiment and elaborates on the differences between the representational conditions. We describe our feature extraction process and modeling decisions in Section \ref{sec:method}. Section \ref{sec:results} summarizes the results of the model estimation and statistical analysis of the effects of multiple representations at the population and sub-population levels. We  suggest profitable future directions in Section \ref{sec:conclusion}.

\section{Experiment}
\label{sec:experiment}

In the Spring of 2010, Rau conducted an experiment wherein 290 $4^\text{th}$ and $5^\text{th}$ grade students worked with a Fractions Tutor for about 5 hours of their mathematics instruction. Students were randomly assigned to one of five experimental conditions, which varied by the frequency with which students would be presented with a new fraction representation (see Figure \ref{fig:condition-graph}). Students in the \mgr{Single} representation condition worked exclusively with either a number line, a circle or a rectangle. Students in the \mgr{Fully Interleaved} condition saw a different representation than was used in the preceding problem. Students in the intermediate conditions went longer before seeing a different representation.   
\begin{figure}[htbp]
\centering
\includegraphics[scale=.4]{conditionGraph.png}\\
\caption{A partial ordering of experimental conditions by the frequency with which a new representation is presented. }
\label{fig:condition-graph}
\end{figure}

When interacting with different graphical representations of fractions, students were able to drag-and-drop slices of a pie chart, for example, into separate areas. They were also able to experiment with changing the number of subdivisions in each graphical representation. Students received a pre-test on the day before they began working with the tutor and an immediate post-test on the day after they finished. Students also took a delayed post-test a week after the first. Previous investigation found that students in the MGR conditions significantly outperformed students in the single representation condition on the delayed post-test \cite{Rau2012,Rau2012b}. 

%\section{Related Work}
%\label{sec:related-work}

%Latent Class Analysis and other clustering tools have commonly been used to analyze educational data. LSA can be used either for explanatory or confirmatory purposes. An application of clustering for educational data is presented in \cite{Merceron2005}, where students were clustered by types of mistakes. The authors suggested that identifying the different types of learners could help teachers apply remedial methods. Similarly, \cite{Perera2009} applied clustering techniques to group teams of students by the amount of work they performed. With LSA techniques they were able to reduce seven groups to three clusters. \cite{Maas2008} provided a comparative analysis of simulated data for Rule Assessment Methodology and LSA. They found five classes with conditional probabilities close to 0.95. They also found that the five classes worked better with RAM than the previous class definitions. Finally, \cite{Su2006} proposed a four-phase learning portfolio mining (LPM) approach, which uses sequential pattern mining, clustering and decision tree creation to find features from the portfolio and predict which group a new learner belongs to. Additional techniques used in educational data mining can be found in \cite{Romero2007}.
 
\section{Method}
\label{sec:method}

We proceed in three stages: (1) we extract features characterizing error and hint-seeking behavior from the data logs, (2) we transform the longitudinal log data into a cross-sectional form, with one observation per student, and (3) we estimate a mixture model to identify sub-populations of students, using AIC and BIC to select the number of classes. 

Once we have clustered our students by their learning strategy, we investigate the interaction between the strategies and the experimental conditions. We construct a contingency table binning the experimental conditions into the clusters estimated by the mixture model. We then run a Chi-squared test for independence between experimental condition and learning strategy. Chi-squared tests are also run to investigate dependence between pre-test outcome and strategy, strategy and post-test outcome and the conditional dependence of outcome and experimental condition, given a strategic profile.

\subsection{Extracting Features}
The Fractions Tutor captures a detailed log of each student's interactions with the tutor. It stores a time series of correct and incorrect answers, hint requests, interface selections and durations between interactions. Previous analysis \cite{Rau2012} extracted the average number of errors made per step, the average number of hints requested per step, and the average time spent per step from the log data. These variables were used to characterize gross behavioral strategies and dispositions. Similarly, we include the average number of hints requested (\ftr{HintsRequested}) and number of errors (\ftr{NumErrors}) made per \emph{problem} by each student. We also extract the average number of bottom-out hints (\ftr{NumBOH}) per student per problem -- this is the average number of times a student exhausts the available hints in a given problem. We also note that it is not always the average of these features that best characterizes a student. For example, examination of the distribution of hints requested per step across experimental condition, shows a telling picture.
\begin{figure*}[t!]
\centering
\includegraphics[scale=.48]{hintsByStep2.png}\\
\caption{The $x$-axis represents the $n_{th}$ interaction with the tutor across all problems. The $y$-axis is the total number of hints requested at the $n_{th}$ step.}
\label{fig:hints-geom}
\end{figure*}

Note that students who received only one representation start out requesting the fewest hints, but students in the moderate condition eventually need fewer  (see Figure \ref{fig:hints-geom}). Also, students in the interleaved condition tend to request many hints in the early steps of a problem, potentially reflecting the cognitive load associated with translating between representations \cite{Ainsworth1999}. Such considerations suggested that exploiting the timing of student interactions within a problem might expose structural features obscured by stepwise averages (as used in \cite{Rau2012}).  We fit geometric distributions to the number of steps taken before the first hint request (\ftr{FirstHintGeometric}) and to the number of errors before the first hint (\ftr{StubbornGeometric}). The estimated parameter is used to characterize the student's hint-seeking propensity in general and hint-seeking propensity when faced with adversity. For example, students in the first quintile of \ftr{StubbornGeometric} seek help soon after making a mistake, whereas students in the fifth quintile don't change their hint-seeking behavior even after making a large number of errors. Students in the first quintile of \ftr{FirstHintGeometric} are likely to request hints early in a problem, whereas students in the fifth quintile are unlikely to request hints at any point.
\begin{table*}[htbp]
\caption{Summary Statistics for Variables Used in Clustering}
\begin{center}
\begin{tabular}{| l || c | c || c | c | c || c | c | c | c | c |}
\hline
&mean& sd&median&min&max&20\%&40\%&60\%&	80\%&100\%\\ \hline \hline
\ftr{HintsRequested}&0.78&1.27&0.34&0&11.22&0.06&0.19&0.5&1.31&11.22\\ \hline
\ftr{NumErrors}&2.21&1.27&1.92&0.34&8.39&1.15&1.7&2.18&3.19&8.39\\ \hline 
\ftr{FirstHintGeometric}&0.35&0.27&0.27&0.04&1&0.13&0.2&0.33&0.57&1\\ \hline
\ftr{Stubborn Geometric}&0.36&0.21&0.31&0.07&1&0.19&0.27&0.38&0.47&1\\ \hline
\ftr{NumBOH}&0.04&0.08&0&0&0.62&0&0&0.01&0.05&0.63\\ \hline
 \end{tabular}
\end{center}
\label{tab:sumstats}
\end{table*}

\subsection{Expectation-Maximization Clustering}
\label{sec:EM-clust}

Expectation-Maximization (EM) clustering is a modeling technique that determines subtypes based on multinomial distributions. We use the model to categorize students into subpopulations using discretized versions of the features described above. Table \ref{tab:sumstats} shows summary statistics and cut-off points for the extracted features. The model maps a set of observed categorical variables onto a set of inferred classes. 

We note that the categorical nature of the model has the potential to add some noise, since we must select numeric cutoffs to transform our variables into nominals. However, categorical models can offer greater interpretability by allowing us to organize our data into a small set of variables, which forms the basis for categorizing students into a small set of meaningful, homogenous groups. Furthermore, it is not unreasonable to suspect that our variables are in some sense ``truly'' categorical \cite[pp8--9]{Collins2009}. EM clustering requires a relatively small set of variables to train the model. As the number of training variables increases, the number of model parameters blows up and the model becomes overspecified.

%The formal representation of LSA begins with $j = 1 \ldots J$ observed variables, where each such variable $j$ has a set of response variables $r_{j} = 1,\ldots,R_{j}$. Each student has a distinct response pattern $y = (r_{1},\ldots,r_{j})$.

%Now we need to consider the latent classes. Let $L$ be a latent variable with latent classes $c~=~1,\ldots,C$. Furthermore, let $\gamma_{c}$ be the probability of membership in class $c$. Note that latent classes are exhaustive and mutually exclusive, so each student is a member of exactly one latent class. We also need to define the item-response probability $\rho_{j,r_{j}|c}$, which is the probability of response $r_{j}$ to observed variable $j$, conditional on membership in latent class $c$. Each student provides exactly one response alternative to variable $j$. Given these constraints, note that
%\[ \sum_{c=1}^{C} \gamma_{c} = 1,\quad \sum_{r_{j}=1}^{R_{j}} \rho_{j,r_{j}|c} = 1. \] 

%Now that we have defined key variables, we can define the probability of observing a particular response vector based on the $\gamma$'s and $\rho$'s:
%\begin{align}
%P(Y = y) = \sum_{c=1}^{C} \gamma_{c} \prod_{j=1}^{J} \prod_{r_{j}=1}^{R_{j}} \rho_{j,r_{j}|c}^{I(y_{j} = r_{j})}
%\label{eqn:LSA-final}
%\end{align}
%where the indicator function $I(y_{j} = r_{j})$ equals 1 when the response variable $j = r_{j}$. The parameters $\gamma_{c}$ and $\rho_{j,r_{j}|c}$ are estimated by EM. Since EM is sensitive to starting probabilities, we pick the maximum likelihood over twenty-five runs. LSA is very similar to other EM-based algorithms. In fact, LSA is an application of multivariate mixture estimation using categorical variables with an additional local independence assumption, meaning that the observed variables are independent of each other conditional on the latent variable. This is a simplifying assumption similar to the one made in Naive Bayes classification models; without it Equation \ref{eqn:LSA-final} would have to be much more complicated. There is some work on relaxing this independence assumption \cite{Hagenaars1988,Garrett2004}. For more details on the formalism and its applications, see \cite{Collins2009}. To run latent class analysis, we used \texttt{poLSA}, a freely available R package\footnote{\url{http://userwww.service.emory.edu/~dlinzer/poLSA/}}.

Unlike some common clustering algorithms (e.g., k-means), EM produces ``fuzzy'' clusters (i.e., probability distributions over features for each class). We use these probability distributions in our qualitative discussion about the subpopulations (Section \ref{sec:exploring-classes}), however we ultimately need to identify each student's most likely class. For each student $s$ and class $c$ we calculate
\begin{align}
\argmax_{c} P(S = s \;|\; C = c)
%\argmax_{c} P(Y = y \;|\; L = c) = \argmax_{c} \gamma_{c} \prod_{j=1}^{J} \prod_{r_{j}=1}^{R_{j}} \rho_{j,r_{j}|c}^{I(y_{j} = r_{j})}
\label{eqn:LCA-argmax}
\end{align}
where the probabilities are determined by the EM algorithm.

We still need to fix $N$, the number of classes. We use two complexity-penalized log-likelihood scores to select an appropriate $N$: Akaike information criterion (AIC) and Bayesian information criterion (BIC). Plotting these statistics as we increment the number of classes, we look for a ``knee'' where both statistics either bottom-out or level off to identify the optimal value of $N$. To run analysis, we used \texttt{poLCA}, a freely available R package.\footnote{\url{http://userwww.service.emory.edu/~dlinzer/poLCA/}}
\\\\
\section{Results}
\label{sec:results}

In the sections that follow we analyze the results of our clustering algorithm. We describe the strategic profiles that were generated and characterize the students fitting each profile. We then consider the relationships between our variables of interest: 
\begin{inparaenum}[\itshape (a)]
\item adjusted delayed post-test score,
\item experimental condition, and
\item learning strategy.
\end{inparaenum}
Specifically, we run a series of Chi-squared tests for independence to determine how each variable relates with the others, commenting on the importance of each comparison. Finally, we explore the stability of these classes, which bears on whether future systems could detect students' strategic profiles in real time.

\subsection{Exploring the Learning Strategies}
\label{sec:exploring-classes}

Figure \ref{fig:LCa-test-statistics} shows the parameter selection process described in Section \ref{sec:EM-clust}. Note that we chose to model four classes because BIC bottoms out and AIC levels off at that point.

\begin{figure}[htbp]
%\centering
\includegraphics[scale=0.4]{lca-stats-plot.png}
\caption{AIC and BIC over increasing number of clusters. BIC bottoms out and AIC levels off at four clusters, so we conclude that four clusters best fits the data.}
\label{fig:LCa-test-statistics}
\end{figure}

After selecting the appropriate $N$ parameter, we extract membership probabilities for the individual students. Given a strategic profile, we can estimate the probability distribution over each feature, and use Equation \ref{eqn:LCA-argmax} to identify the most likely profile for each student.

The feature distributions over each profile are represented graphically in Figure \ref{fig:LCA-class-viz}. Each feature is listed along the horizontal $x$-axis, the value each variable takes is along the front-to-back $y$-axis, and the probability that the feature takes that value is given along the vertical $z$-axis. For example, consider the \ftr{HintsRequested} feature (average hints requested per problem) in the ``interactive'' class. In that class, with high probability, students requested many hints (i.e., the highest categorical value for hints) per problem on average. As another example, students in the ``moderate'' class are more likely to make a moderate number of errors, though other error levels also occur with nontrivial probabilities. Lower values of \ftr{FirstHintGeometric} and \ftr{StubbornGeometric} indicate a steep geometric slope, corresponding to a higher hint-seeking propensity and stubbornness, respectively.

How do we interpret cluster membership? Students in Class 1 are ``Moderate'', they ask for a moderate number of hints, make a moderate number of errors, and are moderately responsive to the interface. Students in Class 2 are ``Interactive'', they make a lot of errors, but respond by requesting many hints. These students are proactive in asking for help and are not shy about using the resources the Fractions Tutor makes available. Students in Class 3 are ``Confident'', they don't ask for hints, but they don't seem to need them (since they make few errors). Finally, we call students in Class 4 ``Stubborn'' because they are fairly mixed in error-profile but they don't respond to mistakes with hint-requests. These students are not using all the resources that the Fractions Tutor makes available.

\begin{figure*}[t]
\centering
\includegraphics[scale=0.5]{lca-class-viz.png}
\caption{Visualization of feature distributions for each learning profile. The left-to-right $x$-axis identifies each feature, the front-to-back $y$-axis identifies which value that feature takes, and the top-to-bottom $z$-axis describes the probability that the feature takes the value. Thus, given a feature and a class, the $z$-axis also describes the probability distribution over that feature in that class.}
\label{fig:LCA-class-viz}
\end{figure*}


\subsection{Condition and Outcome} 
We use normalized learning gain at the delayed post-test as our measure of student improvement. 
\begin{center}
\textsc{Learning Gain} = \scalebox{1.2}{$\frac{\text{\textsc{DelayedPostTest}} - \text{\textsc{PreTest}}}{1-\text{\textsc{PreTest}}}$}
\end{center}

We then construct terciles of the Adjusted Delayed Post-Test Score and run a Chi-squared test for independence of outcome from experimental condition. Confirming previous results, we reject independence at a $p$-value of .024 (see Table \ref{tab:exp-and-score}). As expected, students in the multiple representation conditions were more likely to be in the second or third tercile of adjusted delayed post-test score, whereas students in the single representation condition were more likely to be in the first.

\begin{table}[hbtp]

\centering
\begin{tabular}{|l || c | c | c |}
\hline
&33\%&66\%&99\%\\ \hline \hline
  \textbf{blocked}  &   14& 29& 20 \\ \hline
  \textbf{increased}&   22& 20& 20 \\ \hline
\textbf{interleaved}& 13& 21& 18 \\ \hline
  \textbf{moderate} &   18& 13& 22 \\ \hline
    \textbf{single} &      30& 13& 17 \\ \hline
 \end{tabular}
  \begin{center} $\mathcal{X}^2$ = 17.65, df = 8, p-value = {\bf 0.024} \end{center}
 \caption{Experimental Condition by Tercile of Adjusted Delayed Post-Test Score.}
\label{tab:exp-and-score}
\end{table}


%\newpage
\subsection{Learning Strategy and Test Scores}

We would expect that a student's learning strategy would predict (and perhaps cause) their ultimate educational outcome. To test this intuition, we calculate a Chi-squared statistic for independence of learning strategy from normalized delayed post-test gain. We reject independence at a $p$-value of .0075 (see Table \ref{tab:LS-by-score}). The behaviors encoded by strategic profile seem highly relevant to knowledge consolidation in the long run. Students in the moderate class are found mostly in the second and third tercile. These students are implementing a subtle but effective strategy. Their moderation in hint-seeking indicates a level of self-reflectiveness that we would expect from students with highly developed metacognitive skills. Students in the interactive class are characterized by a high number of errors, so we are not surprised to find them represented mostly in the first and second terciles. These students are the most likely to exhaust all the hints available in a given problem. If one were looking for students engaging in ``gaming'' behavior this would be the class to search, perhaps using techniques from \cite{Baker2009b}. As one would expect, the confident  students are likely to end up in the third tercile. The stubborn students are clustered at the extremes: they are more likely to end up in the first or third tercile than the second. 

\begin{table}[hbtp]
\centering
\begin{tabular}{|l || c | c | c | c | c | c |}
\hline
& \multicolumn{3}{c|}{Learning Gain} & \multicolumn{3}{c|}{Pre-Test} \\ \cline{2-7}
&33\%&66\%&99\%&33\%&66\%&99\%\\ \hline \hline
  moderate   &   20& 35& 29 & 30 & 32 & 22 \\ \hline
  interactive &   33& 26& 14 & 37 & 27 & 9\\ \hline
confident & 13& 15& 22 &5 & 14 & 31\\ \hline
  stubborn & 31& 20& 32 & 26 & 22 & 35 \\ \hline
 \end{tabular} \\
Learning Gain: $\mathcal{X}^2$ = 17.52, df = 6, p-value = {\bf 0.0075} \\
Pre-Test: $\mathcal{X}^{2}$ = 42.3764, df = 6, p-value = {\bf <0.001}
\caption{Learning Strategy by Tercile of Normalized Delayed Post-Test and Pre-Test Score}
\label{tab:LS-by-score}
\end{table}

Although we implicitly account for the pre-test scores in our learning gain metric, we also investigate the relationship between learning strategy and pre-test scores (Table \ref{tab:LS-by-score}). As expected, we reject independence between strategic profile and pre-test score, suggesting that these profiles are genuinely meaningful descriptions of student behavior.

Although pre-test score and strategic profile are dependent, the average pre-test score for the ``stubborn'' students does not differ significantly from the rest of the population.\footnote{Student's T-test: t = 0.9978, df = 139.602, p-value = 0.3201} Pairwise t-tests between the four profiles show significant differences in mean pre-test score for all pairs except stubborn and moderate. This analysis suggests that the dependence we detect between experimental condition and outcome for the ``stubborn'' students does not hinge essentially on pre-test score. If pre-test is an accurate proxy for preparedness, the stubborn students do not occupy a preparedness ``sweet-spot'' that makes multiple representations uniquely effective. Rather, it seems to be their unique strategic profile that accounts for the effectiveness of MGRs.

%\begin{table}[hbtp]
%\centering
%\begin{tabular}{|c|c|c|c|}
%\hline
%		 & Stubborn & Clever & Medium \\ \hline
%Clever   & $<.005$ &\cellcolor{Gray} & \cellcolor{Gray} \\ \hline
%Medium   & .342 & $<.005$ & \cellcolor{Gray} \\ \hline
%Interactive & $<.005$ & $<.005$ & $<.005$ \\ \hline
%\end{tabular}
%\caption{Correlation Matrix}
%\label{tab:correlations}
%\end{table}



\subsection{Condition and Learning Strategy}

We may also worry that experimental condition is inducing learning strategy. If this were the case, we would suspect that we were picking up on artifacts of the experimental design rather than pre-existing student profiles. However, using the Chi-squared test, condition and cluster membership appear independent (see Table \ref{tab:exp-and-LS}).\footnote{We fail to reject independence at a $p$-value of $.38$.}  To anticipate Simpson's paradox-type worries, we collapse all four multiple representation conditions (blocked, moderate, increased, interleaved) into a single ``multiple representation'' condition, but still find independence.\footnote{$\mathcal{X}^{2}$ = 1.1517, df = 3, p-value = 0.7646} These results suggest that our method is detecting genuine student profiles, independent of experimental condition. 


\begin{table}[hbtp]
\centering

\begin{tabular}{|l || c | c | c | c |}
\hline
& mod. & inter. & conf. & stub. \\ \hline \hline
\textbf{blocked}&     13& 15& 10& 25\\ \hline
\textbf{increased}&   21& 16& 10& 15\\ \hline
\textbf{interleaved}& 17& 18&  7& 10\\ \hline
\textbf{moderate}&    18& 10& 12& 13\\ \hline
\textbf{single}&      15& 14& 11& 20\\ \hline
 \end{tabular}
 
 \begin{center} $\mathcal{X}^2$ = 12.85, df = 12, p-value = 0.38 \end{center}
\caption{Experimental Condition by Learning Strategy}
\label{tab:exp-and-LS}
\end{table}






\begin{table*}[htbp]
 \begin{center}
\begin{tabular}{|l || c | c | c |}
\hline
\emph{moderate} &33\%&66\%&99\%\\ \hline \hline
  \textbf{blocked}&      2&  8& 3\\ \hline
\textbf{increased}&    4&  9&  8 \\ \hline
  \textbf{interleaved}&  4&  9&  4 \\ \hline
     \textbf{moderate}&     4&  5& 9 \\ \hline
       \textbf{single}&       6&  4&  5 \\ \hline
 \end{tabular}
\begin{tabular}{|l || c | c | c |}
\hline
\emph{interactive} &33\%&66\%&99\%\\ \hline \hline
  \textbf{blocked}&      7&  6& 2 \\ \hline
\textbf{increased}&    9&  5&  2 \\ \hline
  \textbf{interleaved}&  5&  8&  5 \\ \hline
     \textbf{moderate}&     7&  2& 1 \\ \hline
       \textbf{single}&       5&  5&  4 \\ \hline
 \end{tabular}
\\$\mathcal{X}^2$ = 8.08, df = 8, p-value = 0.43\hspace{15pt}$\mathcal{X}^2$ = 6.95, df = 8, p-value = 0.54\\ \hspace{0pt} \\
\begin{tabular}{|l || c | c | c |}
\hline
\emph{confident} &33\%&66\%&99\%\\ \hline \hline
  \textbf{blocked}&      0&  5& 5 \\ \hline
\textbf{increased}&    3&  3&  4 \\ \hline
  \textbf{interleaved}&  2&  2&  3 \\ \hline
     \textbf{moderate}&     3&  4& 5 \\ \hline
       \textbf{single}&       5& 1&  5 \\ \hline
 \end{tabular}
\begin{tabular}{|l || c | c | c |}
\hline
\emph{stubborn}&33\%&66\%&99\%\\ \hline \hline
  \textbf{blocked}&      5&  10& 10 \\ \hline
  \textbf{increased}&    6&  3&  6 \\ \hline
  \textbf{interleaved}&  2&  2&  6 \\ \hline
  \textbf{moderate}&     4&  2& 7 \\ \hline
  \textbf{single}&       14&  3&  3 \\ \hline
 \end{tabular}
\\$\mathcal{X}^2$ = 7.41, df = 8, p-value = 0.49\hspace{15pt}$\mathcal{X}^2$ = 17.4837, df = 8, p-value = {\bf 0.025}
\end{center}
\caption{Condition and Tercile of Adjusted Delayed Post-Test Score, by Learning Strategy}
\label{tab:exp-and-score-by-LS}
\end{table*}


\subsection{Condition, Outcome and Strategy}

Finally, we explore the relationship between learning outcome and experimental condition for each of the strategic profiles we have identified. Interestingly, we find that experimental condition has a substantial effect on learning outcome among the ``stubborn'' students, but virtually no effect on learning among the ``moderate'', ``interactive'', and ``confident''  (see Table \ref{tab:exp-and-score-by-LS}).  Most students perform in the second and third tercile when given multiple graphical representations, but are overwhelmingly in the first tercile when given a single representation. 

Students in the other three classes are not significantly affected by their representation condition. The learning strategies that these students implement seem to make them resilient to representational choice, at least in this experimental regime. Recall that students exhibiting the ``stubborn'' profile rarely requested hints, even when they encountered difficulty. We speculate that they lack the metacognitive skills to judge when their learning strategies are failing, and thus are not seeking help at appropriate times \cite{Aleven2006}. They are the most sensitive to pedagogical decisions because they are the least equipped to structure and manage their own learning. 

An ITS ought to ensure that these students are targeted with multiple representations, and perhaps other forms of metacognitive support. While not all ``stubborn'' students improve when given MGRs, the vast majority of them do. An ITS might help scaffold effective learning behaviors by spontaneously offering hints to these students when they appear to need them the most. A teacher informed that a student exhibits this learning profile may try to encourage the student to ask for help and target their metacognitive skills more generally. Moreover, studying this sub-population seems to be a promising avenue for illuminating the mechanism by which MGRs improve learning outcomes. Future experiments could test the effect of offering spontaneous hint-support to students that fit the ``stubborn'' profile.

We note that there are competing interpretations of our results that also suggest interesting future experiments. Studies have found that well-designed feedback from errors may be very effective for improving learning outcomes \cite{McKendree1990}. It may be that ``stubborn'' students, by not shying away from mistakes, are taking advantage of a more effective support system than students who avoid mistakes by soliciting hints. Since instruction with multiple representations is generally more difficult, stubborn students in a multiple representation condition would get more of this kind of feedback on average. This interpretation would predict that students in the ``interactive'' profile would benefit if some hints were withheld \cite{Koedinger2007}. However, this hypothesis could only be tested by subsequent experiments.

\subsection{Profile Stability}

\begin{figure}
\includegraphics[scale=.4]{class-stability.png}
\caption{We measure the number of students who were classified into their ultimate strategic profile as the amount of data available to EM is increased. We see that at about 60\% of the data we can classify about 75\% of the students into their ultimate profile.}
\label{fig:class-stability}
\end{figure}

If an intelligent tutoring system could implement our classification methodology on-the-fly, it could tailor its pedagogical interventions to the needs of the individual student. To substantiate the promise of the methodology we investigate how efficiently the algorithm stabilizes to the final classification. To measure this, we first cluster on the entire corpus and assign each student to their most likely profile. We then artificially subset the data by restricting the number of problems seen by the clustering algorithm, compute the proportion of students who are in their ``final'' profile, and then iteratively increase the size of the subset. This simulates how well our algorithm identifies student profiles as they make their way through the material. 

% TODO FIXME wrt num problems
Figure \ref{fig:class-stability} shows the percentage of total data used to estimate the model plotted against the proportion of students assigned to their final strategic profile. At each iteration, we look at an additional 10 problems from each student and re-estimate the cluster assignments. The regression estimates that 63\% of the data is sufficient to classify three quarters of the students into their ultimate cluster. Thus, after seeing about 60 problems -- about two days of classroom instruction -- a dynamic intelligent tutoring system might intervene on students who fit the ``stubborn'' profile by ensuring that they are presented with multiple graphical representations, offering them spontaneous hints or targeting them with some other form of metacognitive support. 

%\newpage
\section{Conclusion \& Future Work}
\label{sec:conclusion}

We estimated an expectation maximization clustering model to classify students into four strategic profiles based on their error-rates and hint-seeking behaviors. We detected an effect of experimental condition on post-test outcome only in the class of students characterized by high-error rate and low hint-seeking propensity. That is, students who did not seem to take full advantage of the resources that the Fractions Tutor offered were the ones most strongly affected by experimental condition. These students may not have the metacognitive skills required to know when to seek hints. 

Our methods could be used by ITS designers to detect students with this profile in real time. Tutoring systems could then intervene to target these students with MGRs, scaffold their hint-seeking behaviors or target them with other forms of metacognitive support. Future research into  the mediating mechanisms of multiple representations could leverage our results to identify the relevant student sub-populations to investigate. Our post-hoc analysis is not designed to identify the cognitive processes underlying the student's problem solving behavior, so interviews or a cognitive task analysis with students who fit the ``stubborn'' profile could reveal more details about their experience than we can detect from the log data. Additional investigation into different features may help further characterize student behavior and could help us more accurately group students into relevant subpopulations. Although our analysis seems to have revealed interesting differences in student learning strategies, more informative features constructed from log data may do better. Constructing more informative features, for example, might allow us to separate the ``stubborn'' students into those who did and did not benefit from multiple graphical representations. 

\bibliographystyle{abbrv}
%\bibliography{references}
\begin{thebibliography}{10}

\bibitem{Ainsworth1999}
S.~E. Ainsworth.
\newblock The functions of multiple representations.
\newblock {\em Computers and Education}, 33(2-3):131--152, 1999.

\bibitem{Ainsworth2006}
S.~E. Ainsworth.
\newblock Deft: A conceptual framework for learning with multiple
  representations.
\newblock {\em Learning and Instruction}, 16(3):183--198, 2006.

\bibitem{Aleven2000}
V.~Aleven and K.~R. Koedinger.
\newblock Limitations of student control: Do students know when they need help?
\newblock In G.~Gauthier, C.~Frasson, and K.~VanLehn, editors, {\em Proceedings
  of the 5th International Conference on Intelligent Tutoring Systems, ITS
  2000}, pages 292--303, 2000.

\bibitem{Aleven2006}
V.~Aleven, B.~McLaren, I.~Roll, and K.~R. Koedinger.
\newblock Toward meta-cognitive tutoring: A model of help seeking with a
  cognitive tutor.
\newblock {\em International Journal of Artificial Intelligence in Education},
  2006.

\bibitem{Aleven2003}
V.~Aleven, E.~Stahl, S.~Schworn, F.~Fischer, and R.~M. Wallace.
\newblock Help seeking and help design in interactive learning environments.
\newblock {\em Review of Educational Research}, 73(2):277--320, 2003.

\bibitem{Ambrose2010}
S.~A. Ambrose, M.~W. Bridges, M.~DiPietro, M.~C. Lovett, and M.~K. Norman.
\newblock {\em {How Learning Works}}.
\newblock Jossey-Bass, 2010.

\bibitem{Baker2009b}
R.~Baker.
\newblock Differences between intelligent tutor lessons, and the choice to go
  off-task.
\newblock In {\em Proceedings of the 2nd International Conference on
  Educational Data Mining}, 2009.

\bibitem{Baker2009}
R.~Baker, A.~Corbett, I.~Roll, and K.~R. Koedinger.
\newblock Developing a generalizable detector of when students game the system.
\newblock {\em User Modeling and User-Adapted Interaction}, 2009.

\bibitem{Beal2008}
C.~R. Beal, L.~Qu, and H.~Lee.
\newblock Mathematics motivation and achievement as predictors of high school
  students' guessing and help-seeking with instructional software.
\newblock {\em Journal of Computer Assisted Learning}, 24:507--514, 2008.

\bibitem{Collins2009}
L.~M. Collins and S.~T. Lanza.
\newblock {\em Latent Class and Latent Transition Analysis: With Applications
  in the Social, Behavioral, and Health Sciences}.
\newblock Wiley Publishing, 2009.

\bibitem{Koedinger2007}
K.~R. Koedinger and V.~Aleven.
\newblock Exploring the assistance dilemma in experiments with cognitive
  tutors.
\newblock {\em Education Psychology Review}, 19:239--264, July 2007.

\bibitem{McKendree1990}
J.~E. McKendree.
\newblock Effective feedback content for tutoring complex skills.
\newblock {\em Human Computer Interaction}, 5:381--414, 1990.

\bibitem{Merceron2005}
A.~Merceron and K.~Yacef.
\newblock Clustering students to help evaluate learning.
\newblock {\em Technology Enhanced Learning}, pages 31--42, 2005.

\bibitem{Newell1981}
A.~Newell and P.~Rosenbloom.
\newblock Mechanisms of skill acquisition and the law of practice.
\newblock {\em Cognitive Skills and Their Acquisition}, 1981.

\bibitem{Perera2009}
D.~Perera, J.~Kay, I.~Koprinska, K.~Yacef, and O.~R. Zaiane.
\newblock Clustering and sequential pattern mining of online collaborative
  learning data.
\newblock {\em Knowledge and Data Engineering, IEEE Transactions},
  21(6):759--772, 2009.

\bibitem{Rau2012}
M.~Rau and R.~Scheines.
\newblock Searching for variables and models to investigate mediators of
  learning from multiple representations.
\newblock In {\em International Conference on Educational Data Mining}, 2012.

\bibitem{Rau2009}
M.~A. Rau, V.~Aleven, and N.~Rummel.
\newblock Intelligent tutoring systems with multiple representations and
  self-explanation prompts support learning of fractions.
\newblock {\em International Conference of Artificial Intelligence in
  Education}, pages 441--448, 2009.

\bibitem{Rau2012b}
M.~A. Rau, V.~Aleven, Z.~Tunc-Pekkan, L.~Pacilio, and N.~Rummel.
\newblock How to schedule multiple graphical representations? a classroom
  experiment with an intelligent tutoring system for fractions.
\newblock In {\em Proceedings of International Conference of the Learning
  Sciences}, 2012.

\bibitem{Self1986}
J.~Self.
\newblock The application of machine learning to student modelling.
\newblock 14(3--4):327--338, 1986.

\bibitem{Amershi2009}
C.~Unsupervised and S.~C. to~Build User Models~for Exploratory
  Learning~Environments.
\newblock Saleema amershi and cristina conati.
\newblock {\em Journal of Educational Data Mining}, 1, 2009.

\end{thebibliography}

\balancecolumns
% That's all folks!
\end{document}
